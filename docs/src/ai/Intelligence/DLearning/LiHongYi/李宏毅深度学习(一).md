# 1、机器学习相关规定

大白话：**机器学习其实就是让机器帮我们找一个函数**。

![](李宏毅深度学习(一).assets/1.png)

- 假设让机器做语音转文本，比如微信的语音转文本，其实就是给机器一段语音作为输入参数，经过一系列的函数f(x)将语音输出为文本。这个函数太复杂了，所以让机器帮我们找出来这个函数。
- 假设让机器做照片识别，比如人脸识别，其实就是给机器一张图片作为输入参数，经过一系列的函数f(x)将图片输出为名字。
- 阿尔法狗也是，给阿尔法狗棋盘落子的位置，输出下一步棋子的位置。

> 那么这门课聚焦于深度学习，深度学习比机器学习更复杂一点，我们给机器的参数是一个**类神经网络**。大白话：**类神经网络有各式各样的输入和各式各样的输出。**
>
> ![](李宏毅深度学习(一).assets/2.png)
>
> - 比如输入向量、矩阵、序列，输出数值、类别、图片、文档等。
>   - 在做图片识别时传入的图片往往是用矩阵来表示的
>   - 在做语音辨识，比如翻译，输入的是一段声音信号，其实这个声音信息就是用序列来表示的

![](李宏毅深度学习(一).assets/3.png)

1. 思考：**机器是怎么来进行找出这个函数呢？**
   - 假如你现在要做一个图片识别器，识别图片是宝可梦还是数码宝贝。机器采用监督学习 Supervised Learning 方式，需要我们准备一大堆的训练资料，比如很多图片，给它标记(Label)这张图片是数码宝贝还是宝可梦。然后根据 Label 标记机器去找一个方向，这个方向的输入是一只动物，输出是告诉我们动物是宝可梦还是数码宝贝。
   - 但是监督学习 Supervised Learning 方式需要我们自己标记，是一个耗费人力是过程，假如你要分猫和狗，分自行车和小轿车，岂不是每个材料都要手工标记？所以采用自我监督学习 Self-supervised Learning，机器需要先练成一些基本功 Pre-train，这个基本功要怎么训练呢？
     - 就图片识别而言，给机器很多的图片资料，图片就可以自己学习了。关于具体细节后面会补充，大概可以这么理解:给机器一张图片，将这张图片上下左右翻转，然后再问机器，这还是刚才那张图片吗，两张图片是一样的吗？等等等等。
     - 当机器在大量没有标注的资料上面，学会分辨图片后，就可以很好的在下游任务上面得到好的结果。下游任务就是我们给机器图片，问机器这张图片是宝可梦还是数码宝贝的任务。

所以我们可以发现，Pre-train 是一个很重要的事情，只有把基本功练好，才能很好的完成我们的下游任务。那么我们把练习基本功过程可以成为 Pre-trained Model 预训练模型或者 Foundation Model 基础模型。



## 1.1、生成式对抗网络GAN

Generative Adversarial Network 生成式对抗网络：

- 在监督学习中，我们需要给机器大量的x，然后给每个x对应的答案y，也就是需要给机器的资料都是成对的，x1对应y1，x2对应y2等。
- 有了GAN生成式对抗网络，我们就可以准备大量的x，准备大量的y，不用给它们成对关联，机器会自动找出它们之间的关联。





## 1.2、强化学习Reinforcement Learning

强化学习发生在标注资料的时候，假如教机器下围棋，给机器说你看到什么样的棋盘式，就下到什么样的位置，就可以用监督学习的方法教机器下围棋。但是人类自己也不知道看到棋盘式下到哪里就是最好的结果，这个时候就用到强化学习Reinforcement Learning 技术了。

- 当你不知道如何标注资料，但你知道如何判断好坏的时候，就可以使用强化学习啦。



## 1.3、异常检测Anomaly Detection

异常检测Anomaly Detection的目的在于让机器知道它所不知道的事情，比如我们只训练宝可梦和数码宝贝，假如给它一张其他非宝可梦和数码宝贝的图片，可以让机器回答出：我不知道。

![](李宏毅深度学习(一).assets/4.png)

## 1.4、可解释性AI Explainable AI

大白话：我们希望机器回答出宝可梦或者数码宝贝，并且再附带解释来告诉我们为什么？



## 1.5、模型攻击 Mode Attack

原始图片经过分类模型，可以正确识别 cat 猫，我们在图片上加入某些一定分布的噪声后，模型可能就会把它错误识别为其他类别。







# 2、机器学习Machine Learning

- 一句话概括：机器学习就是让机器具备找一个函式的能力

## 2.1、专有名词

专有名词：

- Regression(回归)：**要找的这个函式的输出是一个数值**。如下，预测PM2.5的任务，输入是今天的PM2.5值、今天温度、今天臭氧的浓度，输入是明天的PM2.5的值。那么找这个函式的任务就是 Regression。

![](李宏毅深度学习(一).assets/5.png)



- Classification(分类)：**函式的输出，是从设定好的选项里面，选择一个当作输出**。我们给很多选项，称为classes(类)。如下，我们输入是一封邮箱email，通过这个函式，回答出这个email是不是垃圾邮箱。

![](李宏毅深度学习(一).assets/6.png)



- Structured Learning(结构化学习)：结构学习指的是输入和输出都是具有结构化的对象（数列、列表、树、边界框等）。比如一个序列、一个句子、一篇文章等。





## 2.2、找出函式的三个步骤

机器如何找出我们想找到的函数呢？假如我要预测某个频道的明天的观看流量，分为三个步骤：

1. 首先我们给出函数的大致形式，假如是 y = b + wx~1~，这个函式就是我们的Model
   - y是我们准备要预测的东西，也就是这个频道的观看流量数
   - x1是这个频道前一天观看流量数
   - b跟w是未知的参数，是要通过训练去找出来的。我们目前并不知道b和w应该是多少。
   - 我们猜测的是这个函数，往往就来自于对这个问题本质上的了解，也就是 Domain knowledge(领域知识)
2. Define Loss from Training Data(定义训练数据中的损失)：第二个步骤,是我们要定义一个东西叫做Loss,Loss它也是一个Function,这个Function的输入是我们 Model 里面的参数 b 和 w，这个Loss的输出代表本次结果的好坏。
   - 比如取 b为 0.5k，w为1，则 y = 0.5k+1x~1~ ,这个 y 的值就是本次结果的好坏。那么怎么判断是好还是坏呢？那么就要根据我们的训练资料来作为一个标准了，我们的训练资料是2017-2020年这个频道的观看流量。
   - 🔥假如2017/01/01的流量是4.8k，也就是x~1~是4.8k，带入y = 0.5k+1x~1~ 里面，得到函数值为5.3k，也就是预测2017/01/02的流量为5.3k，和我们的真实正确值(这个真实正确的值也叫Label)4.9k比较，正确值和函数预测值比较的绝对值就是误差数e。
   - 将这三年的误差e求和取平均，得到Loss，这个L越大，则说明这组参数b、w越不好，L越小，则b、w参数取的好。

![](李宏毅深度学习(一).assets/7.png)

可以为取不同的b，取不同的w，为不同的b、w来计算L，可以画出等高线图，图上越偏红色系代表L越大，代表b、w取的越差。

![](李宏毅深度学习(一).assets/8.png)



3. Optimization（优化）：找到能让损失函数值最小的参数。具体的寻找方法是 `Gradient Descent`（梯度下降）
   - 第二步我们得到最优的b和w，记为b* 和 w*
   - 假设我们只有一个参数w,画出Loss和w的关系图，我们要找到一个w来让Loss的值最小。
     1. 首先随机选取一个初始值w~0~
     2. 计算在 w=w~0~的时候,w~0~对loss的微分是多少。根据微分（梯度）的方向，改变参数的值，若微分(斜率)是负数，则变大w的值，若微分(斜率)是正数，则减小w的值，这样就可以让Loss变小。(可以理解为在切点有个人，哪边低就向哪边跨出一步)
     3. 跨出的步伐大小取决于W~0~点的斜率大小和 learning rate (学习率的大小η)，这个 η 是我们自己设定的，自己设定的东西叫做 hyperparameters(超参数),跨出的这一步也就是w~0~变为w^1^,这一步的大小为 w1 = w0-`η×微分值`
     4. 反复进行上述结果，不断移动w的位置
     5. 最后可以自己设置上限值，让w停下来，也可以在理想情况下停下来，即微分值为0(极小值点)，w就不会再移动了(但也有可能陷入局部最小值，不能找到全局最小值)。

![](李宏毅深度学习(一).assets/9.png)

> 推广到多个函数：
>
> 1. 随机选取一个初始值w~0~、b~0~
> 2. 计算L和w、L和b的微分
> 3. 不断更新 w 和 b 的值，最终找到最好的 w* 和 b*
>
> ![](李宏毅深度学习(一).assets/10.png)



以上**三个步骤**组合起来称为**训练**。现在是在答案已知的资料上去计算Loss，但真正的重点是预测未来未知的观看次数。我们训练出的Model是看前一天来预测后一天，误差还是比较大的，可否看前七天的数据预测呢？只需要将函式从 y = b+wx~1~ 变为：
$$
y = b + \sum_{j=1}^{7}w_jx_j
$$
x~j~下标j代表的是几天前，j=7也就是7天前，像这种统称为线性模型 Linear Model。











### 2.2.1、定义Model

Linear（线性）的Model太过简单了，对于绝大多数的情况来说x1与y的关系不是简单的线性关系。现实情况中的Model不可能只是一条直线：

- 无论如何调整Model中的参数，都无法用Linear的Model制造属于真实流量的情况。这属于来自Model模型的限制，称为`Model的Bias`，也就是指模型无法模拟真实情况。
- 因此我们需要对Model进行改进，需要一个更加复杂、灵活的，并带有未知参数的Function。

假如真实流量的图是红线，那么这个**红线 = 常数 + 一些蓝线**

![](李宏毅深度学习(一).assets/11.png)

- 红色曲线的**常数项设定为与y轴的交点**。为0号线
- 蓝色曲线1：斜坡和红线开始斜率一致。这样 0号蓝线 + 1号蓝线就得到了红线前半段。
- 蓝色曲线2：斜坡和红线斜坡斜率一致。这样 0号蓝线 + 1号蓝线 + 2号蓝线就得到了红线中间段。
- 蓝色曲线3：斜坡和红线斜坡斜率一致。这样 0号蓝线 + 1号蓝线 + 2号蓝线 + 3号蓝线就得到了全部红线。

**所以红色这个线,可以看作是一个常数,再加上一堆蓝色的 Function**。图中的红色Curves（曲线）都是由许多线段组成的，称为**Piecewise Linear 的 Curves**（分段线性的曲线）。这些曲线都可以用常数+各种蓝色Function组成。**曲线转折越多、越复杂，需要的蓝色Function就越多。**

> **只要有足够的蓝色 Function 把它加起来，就可以变成任何连续的曲线**。

思考：这个蓝色Function如何写出来呢？

![](李宏毅深度学习(一).assets/12.png)

直接写出蓝色Function不容易，但可以用相近的曲线来理解它。**Sigmoid函数**曲线与图中的蓝色Function很相近。Sigmoid函数的公式为
$$
y = c \frac{1}{1+e^{-(b+wx_1)}}
$$


根据极限可知，当x~1~的值趋近于正无穷大的时候，y=c，**Sigmoid函数**曲线会收敛在高度为c的地方。当x~1~的值趋近于负无穷大的时候，y=0，**Sigmoid函数**曲线会收敛在高度为0的地方。**Sigmoid函数**可以简写为：
$$
y = c*sigmoid(b+wx_1)
$$
蓝色的Function也有一个通用名字**Hard Sigmoid**。我们要**组出各种不同的曲线,那我们就需要各式各样合适的蓝色的 Function,**而这个合适的蓝色的 Function怎么制造出来？可以调整`Sigmoid`函数中的参数来制造出不同形状的S型函数。

- 修改w会改变斜率，就会改变斜坡的坡度
- 修改b就可以把这Sigmoid Function左右移动
- 修改c就可以改变它的高度

![](李宏毅深度学习(一).assets/15.png)

所以只要有**不同的 w 不同的 b 不同的 c,你就可以制造出不同的 Sigmoid Function**。把不同的 Sigmoid Function 叠加起来以后，就可以去逼近各种不同的分段性曲线Piecewise Linear 的 Function,然后 Piecewise Linear 的 Function,可以拿来近似各种不同的连续的 Continuous 的 Function。

- 例如我们的四条蓝线Sigmoid表达式如下，则红线 = 0 + 1 + 2 + 3

![](李宏毅深度学习(一).assets/13.png)

于是，我们的函数就从 y = b+w~1~ 变成了：
$$
y = b + \sum_{i} c_i \quad sigmoid(b_i+w_ix_1)
$$
这样我们用不同的b和不同的w，从而得到不同的函式。之前我们提过使用前7天的Model，要想扩展成比较有弹性的Function的话那也很简单，只需要将函数放进`sigmoid()`括号里面即可。只要 只要ci、bi、wij取不同的值就可以变成不同的Function。

![](李宏毅深度学习(一).assets/14.png)

🔥上面解释还是比较抽象，我们举一个具体的例子：如果j=1，2，3，即只考虑前一天、前两天与前三天的例子。

- j=1，2，3，输入就是 **x1 代表前一天的观看人数,x2 两天前观看人数，x3三天前观看人数**
- 每一个 i 就代表一个蓝色的 Function，只是我们现在每一个蓝色的 Function,都用一个 Sigmoid Function 来近似它
- 如下图，三个 Function 的表达式如下：W的第一个下标代表第几个 Sigmoid Function，第二个下标代表前几天。**r1、r2、r3代表的是括号里面的操作。**

![](李宏毅深度学习(一).assets/16.png)



这个式子可以化成矩阵与向量的乘法，令向量r b x分别等于相对应的向量，Weight组成的矩阵为W。

![](李宏毅深度学习(一).assets/17.png)



接下来就可以进行 Sigmoid 了，r1 r2 r3 分别带入到Sigmoid Function进行计算，得到向量a1、a2、a3。



![](李宏毅深度学习(一).assets/18.png)

求得的Sigmoid的输出a还需要乘ci，最后再加上b，得到y，也就是Sigmoid Function。即我们定义的Model。将c1 c2 c3组成向量c，并取其转置，则 `y = b + c^T^ * a`。

![](李宏毅深度学习(一).assets/19.png)



> 总结：x是输入，x 乘上矩阵w加上向量 b 得到向量 r，再把向量 r 透过 Sigmoid Function得到向量 a,再把向量 a 跟乘上 c 的转置加上b就得到y。也就是我们的Model

如果要用线性代数来表示上面的式子的话就是：

![](李宏毅深度学习(一).assets/20.png)

### 2.2.2、定义Loss

第二步就是要为这个新的Function定义一个新的Loss。与之前Linear Model的Loss的定义的方法相同，由于这次参数变多了，就直接**用θ来统设所有的参数，则Loss Function就可表示成L（θ）**。

这个 Loss Function 要问的就是这个 θ 如果它是某一组数值的话,会有多不好或有多好,那计算的方法,**跟刚才只有两个参数的时候,其实是一模一样的**。

- 先给定某一组W、向量b 、向量c^T^,数值b 的值，也就是先给定某一组θ的值，假设你知道 w 的值是多少,把 w 的值写进去 b 的值写进去,c 的值写进去 ,b 的值写进去
- 然后把一种 x 带进去，看看你估测出来的 y 是多少
- 再计算一下跟真实的 Label 之间的差距,你得到一个 e
- 把所有的误差通通加起来,你就得到你的 Loss

### 2.2.3、优化

第三步就是进行优化。与Linear Model方法相同。

现在的 **θ 它是一个很长的向量**,我们把它表示成 θ1、θ2、θ3....，我们现在就是要**找一组 θ，这个 θ 可以让我们的 Loss 越小越好**。

![](李宏毅深度学习(一).assets/21.png)

1. 一开始要**随机选一个初始的数值,**比如θ0。
2. 接下来呢要**计算微分**,把每一个参数都拿去计算对 L 的微分以后，集合起来它就是一个向量。那个向量我们用 **g** 来表示它。
   - 这个向量有一个名字叫做**Gradient（梯度）**。
   - Gradient的表示方法是在 L 前面放了一个**倒三角形**，这个就代表这是一个Gradient。,L 前面放一个倒三角形的意思就是,把所有的参数 θ1 θ2 θ3,通通拿去与 L 作微分，算微分的位置是θ0的地方。
3. 算出这个 g 以后，我们需要Update 参数**，更新的方法,跟刚才只有两个参数的状况是一模一样的，只是从更新两个参数，可能换成更新成 1000 个参数。**



在实际操作中，我们在求Gradient的时候，如果手里有N个数据，一般会把这N个数据分成一个一个的Batch(一批)，也就是对N个数据进行分组，设每个Batch中有B个数据。

- 过去算Loss的时候是把所有的Data都拿出来进行计算，但是现在可以先只拿一个Bitch里面的Data来算Loss，先设其为L1，**根据这个 L1 来算 Gradient，用这个 Gradient 来更新参数**
- 接下来再选下一个 Batch 算出L2，根据L2 算出 Gradient，然后再更新参数
- 再取下一个 Batch 算出 L3，根据 L3算出 Gradient，再用 L3 算出来的 Gradient 来更新参数

**所以我们并不是拿L来算Gradient。**把所有的 Batch 都算过一次，叫做一个 Epoch(纪元)，每一次更新参数叫做一个Update。



### 2.2.4、实例

假设我们有10000个Data,也就是**N=10000**,假设我们的 **Batch 的大小是设10**,也就 B=10。接下来问,我们在一个 Epoch 中，总共 Update 了几次参数?

1. Batch共有 10000/10 = 1000 个，所以在一个纪元里面，已经更新了参数1000次。



### 2.2.5、模型变型

其实还可以对模型做更多的变形，原本的Model（即Hard Sigmoid）不一定必须要转换成Sigmoid，还有其他的转换方法。可以使用ReLU(读作瑞露)

![](李宏毅深度学习(一).assets/22.png)

比如图中的这个Hard Sigmoid，可以看作**两个Rectified Linear Unit（ReLU 修正线性单元）的结合**。它有一个水平的线，走到某个地方有一个转折的点，然后变成一个斜坡，这种 Function 的式子写成  `c * max(0,b+wx~1~)`

![](李宏毅深度学习(一).assets/23.png)

把两个ReLU 叠加起来,就可以变成 Hard Sigmoid，你想要用 ReLU 的话,就把图中的Sigmoid（）换成max（）即可。那原本Model中需要i个 sigmoid 求和，替换成 ReLU 则需要 2i 个 max 的求和。也就是一个sigmoid可以做到的事情，ReLU需要两倍。当然，表示Hard sigmoid不仅仅只有这两种方法。像Sigmoid 或是 ReLU 这类Function在机器学习里面统称为**Activation Function**(激活函数)。

- 所谓激活函数，就是在人工神经网络的神经元上运行的函数，负责将神经元的输入映射到输出端。

### 2.2.6、模型改进

![](李宏毅深度学习(一).assets/24.png)

x -> a的过程我们可以多做几次，刚才从x 到 a 做的事，就是x*w+b，再通过Sigmoid Function。不过我们现在已经知道不一定要通过 Sigmoid Function，通过 ReLU 也可以得到a。





### 2.2.7、总结

![](李宏毅深度学习(一).assets/25.png)

- Model中的Sigmoid或ReLU称为**Neuron（神经元）** ，多个神经元连起来就是**Neural Network（神经网络）**
- 图中每一列的神经元组曾 **hidden layer(隐藏层)**，多个Hidden Layer就组成了Deep；以上的整套技术就称为**Deep Learning（深度学习）**
- 深度学习的层数也不能太多，太多会导致**Overfitting**(过拟合)，也就是在训练集上表现的好，但是在测试集上表现差。





















https://diamond-mule-bee.notion.site/01-Regression-db3f17ba626a43668e016d09d39e35e5#60d59d4f77de4fdaa043088c3960011a



https://zhuanlan.zhihu.com/p/338627175





https://zhuanlan.zhihu.com/p/435603452







https://www.zhihu.com/column/c_1444802181437931520



https://zhuanlan.zhihu.com/p/398323656



https://diamond-mule-bee.notion.site/01-Regression-db3f17ba626a43668e016d09d39e35e5#60d59d4f77de4fdaa043088c3960011a































